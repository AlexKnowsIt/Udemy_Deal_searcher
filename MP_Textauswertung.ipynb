{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlexKnowsIt/Udemy_Deal_searcher/blob/master/MP_Textauswertung.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "znZszur1nQEc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from openai import OpenAI\n",
        "import json\n",
        "import time\n",
        "import datetime\n",
        "import openpyxl\n",
        "import os\n",
        "import re\n",
        "import string\n",
        "from openpyxl import load_workbook\n",
        "\n",
        "folder_path = '/content/drive/My Drive/MP_Textauswertung'\n",
        "if not os.path.exists(folder_path):\n",
        "    os.makedirs(folder_path)\n",
        "\n",
        "####\n",
        "source_file_path = '/content/drive/MyDrive/Colab Notebooks/Test-Daten-4.xlsx'\n",
        "####\n",
        "\n",
        "working_file_path = os.path.join(folder_path, 'working_file.xlsx')\n",
        "df = pd.read_excel(source_file_path, engine='openpyxl', sheet_name=0)\n",
        "\n",
        "if os.path.exists(working_file_path):\n",
        "    with pd.ExcelWriter(working_file_path, engine='openpyxl', mode='a', if_sheet_exists='new') as writer:\n",
        "        df.to_excel(writer, sheet_name='New Sheet', index=False)\n",
        "else:\n",
        "    df.to_excel(working_file_path, index=False)"
      ],
      "metadata": {
        "id": "mw68Vq70nQtK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. \"source_file_path\" zu dem Path ändern aus dem die Datei kommt\n",
        "2. df = pd.read_excel(source_file_path, engine='openpyxl', **sheet_name=0**) -> 0 = erstes sheet in der Datei"
      ],
      "metadata": {
        "id": "JzxFnITGoV7U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "key_column = 'key' # Column name for the ID to limit going through certain columns\n",
        "wait_time = 1 # wait time in seconds (to limit API use to not get rate limited)\n",
        "openai_api_key = ''  # OpenAI API key"
      ],
      "metadata": {
        "id": "QzEQ7eHppXtW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def call_api_3(prompt):\n",
        "    # Wait for a specified time before making the API call\n",
        "    time.sleep(wait_time)\n",
        "    client = OpenAI(api_key=openai_api_key)\n",
        "\n",
        "    try:\n",
        "        # Making the call to the GPT-3 API\n",
        "        chat_completion = client.chat.completions.create(\n",
        "            model= \"gpt-3.5-turbo\",\n",
        "            messages=[\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": prompt\n",
        "                }\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        # Extracting the text response\n",
        "        api_response = chat_completion.choices[0].message.content.strip() if chat_completion.choices else 'No response'\n",
        "\n",
        "        # Preparing the response data\n",
        "        response_data = {\n",
        "            'prompt': prompt,\n",
        "            'response': api_response\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        # If there's an error, return the entire error message\n",
        "        response_data = {\n",
        "            'prompt': prompt,\n",
        "            'response': str(e)\n",
        "        }\n",
        "\n",
        "    return response_data\n",
        "\n",
        "\n",
        "def call_api_4(prompt):\n",
        "    # Wait for a specified time before making the API call\n",
        "    time.sleep(wait_time)\n",
        "\n",
        "    # Initialize the OpenAI client with the provided API key\n",
        "    client = OpenAI(api_key=openai_api_key)\n",
        "\n",
        "    try:\n",
        "        # Making the call to the GPT-4 API\n",
        "        chat_completion = client.chat.completions.create(\n",
        "            model=\"gpt-4-1106-preview\",  # Updated model name for GPT-4\n",
        "            messages=[\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": prompt\n",
        "                }\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        # Extracting the text response\n",
        "        api_response = chat_completion.choices[0].message.content.strip() if chat_completion.choices else 'No response'\n",
        "\n",
        "        # Preparing the response data\n",
        "        response_data = {\n",
        "            'prompt': prompt,\n",
        "            'response': api_response\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        # If there's an error, return the entire error message\n",
        "        response_data = {\n",
        "            'prompt': prompt,\n",
        "            'response': str(e)\n",
        "        }\n",
        "\n",
        "    return response_data\n",
        "\n",
        "def call_api_test(prompt):\n",
        "    responses = [\n",
        "        \"test1; test2; test3\",\n",
        "        \"test4; test2; test3\",\n",
        "        \"test4; test5; test3\",\n",
        "        \"test4; test5; test6\"\n",
        "    ]\n",
        "\n",
        "    index = len(prompt) % 4\n",
        "    api_response = responses[index]\n",
        "\n",
        "    response_data = {\n",
        "        'prompt': prompt,\n",
        "        'response': api_response\n",
        "    }\n",
        "\n",
        "    return response_data"
      ],
      "metadata": {
        "id": "-kq0ap6dqi1u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_column_topics(key, context, subject, content_column, max_number=None):\n",
        "    # Add a check for key_column existence\n",
        "    if key_column not in df.columns:\n",
        "        raise ValueError(f\"Key column '{key_column}' does not exist in the DataFrame.\")\n",
        "\n",
        "    # API4 instruction - designed to be clear yet editable\n",
        "    api4_instruction = f\"Nennen die {subject} des Textes. Führen Sie sie durch Semikolon ';' getrennt auf. Deine Antwort besteht nur aus {subject}, die durch Semikolon ';' getrennt sind.\"\n",
        "\n",
        "    # Step 1: Extract topics from the whole column using API4\n",
        "    matching_rows = df[df[key_column] == key]  # Filter rows matching the key\n",
        "    responses = matching_rows[content_column].tolist()[:max_number]\n",
        "    question = content_column  # The content column is treated as the question\n",
        "\n",
        "    whole_column_prompt = (\n",
        "        f\"{api4_instruction}\\n\\n\"\n",
        "        f\"{question}: \" + \" ###### \".join(str(response) for response in responses) + \" ######\\n\\n\"\n",
        "        f\"{context}\\n\\n\"\n",
        "        f\"{api4_instruction}\"\n",
        "    )\n",
        "    api_result_whole = call_api_4(whole_column_prompt)  # Ensure this function is defined\n",
        "\n",
        "    # Step 2: Populate the Topics List\n",
        "    topics = api_result_whole['response'].split(';')\n",
        "    topics = [topic.strip() for topic in topics if topic.strip()]\n",
        "\n",
        "    processed_rows = []  # To store processed data\n",
        "\n",
        "    # API3 instruction\n",
        "    api3_instruction = f\"Bestimme die {subject} aus der vorgegebenen Liste, die im Text vorkommen. Führe die {subject} durch ';' getrennt auf. Deine Antwort besteht nur aus {subject}, die durch Semikolon ';' getrennt sind.\"\n",
        "\n",
        "    # Step 3: Iterate through the matching elements in the column using API3\n",
        "    processed_count = 0  # Counter for the number of processed rows\n",
        "    for _, row in matching_rows.iterrows():\n",
        "        review = row[content_column]\n",
        "        row_data = {\n",
        "            'prompt': \"Skipped\",\n",
        "            'response': \"Skipped\",\n",
        "            'response_topics': \"Skipped\"\n",
        "        }\n",
        "\n",
        "        # Check if review is not a string or is an empty/whitespace string\n",
        "        if not isinstance(review, str) or not review.strip():\n",
        "            processed_rows.append(row_data)\n",
        "            continue\n",
        "\n",
        "        # Construct the prompt for API3\n",
        "        topics_str = '; '.join(topics)\n",
        "        full_prompt = (\n",
        "            f\"Frage: {question}\\n\"\n",
        "            f\"------ **ANFANG DES TEXTES** ------\\n\"\n",
        "            f\"{review}\\n\"\n",
        "            f\"------ **ENDE DES TEXTES** ------\\n\\n\"\n",
        "            f\"{api3_instruction}\\n\"\n",
        "            f\"Bereits vorhandene Themen:\\n{topics_str}\\n\\n\"\n",
        "            f\"> \"\n",
        "        )\n",
        "\n",
        "        api_result_row = call_api_3(full_prompt)  # Ensure this function is defined\n",
        "\n",
        "        # Convert response topics from string to list\n",
        "        response_topics = api_result_row['response'].split(';')\n",
        "        response_topics = [\n",
        "            topic.translate(str.maketrans('', '', string.punctuation)).lower().strip()\n",
        "            for topic in response_topics if topic.strip()\n",
        "        ]\n",
        "\n",
        "        # Prepare row data for final DataFrame\n",
        "        row_data = {\n",
        "            'prompt': api_result_row['prompt'],\n",
        "            'response': api_result_row['response'],\n",
        "            'response_topics': response_topics\n",
        "        }\n",
        "        processed_rows.append(row_data)\n",
        "\n",
        "        # Increment the processed row counter\n",
        "        processed_count += 1\n",
        "        if max_number is not None and processed_count >= max_number:\n",
        "            break\n",
        "\n",
        "    # Step 4: Assemble and Save DataFrame\n",
        "    result_df = pd.DataFrame(processed_rows)\n",
        "\n",
        "    # Add columns for each topic and mark presence in each row\n",
        "    for topic in topics:\n",
        "        # Ensure the column exists before applying the lambda function\n",
        "        if 'response_topics' not in result_df.columns:\n",
        "            result_df['response_topics'] = pd.Series([[] for _ in range(len(result_df))])\n",
        "        result_df[f\"topic: {topic}\"] = result_df['response_topics'].apply(lambda x: 1 if topic.lower() in (t.lower() for t in x) else 0)\n",
        "\n",
        "    # Generate a current datetime string for the sheet name\n",
        "    current_datetime = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    cleaned_content_column = re.sub(r'[^\\w\\s-]', '', content_column)\n",
        "    sheet_name = f\"{cleaned_content_column} - {current_datetime}\"\n",
        "\n",
        "    # Save the processed data to an Excel file\n",
        "    with pd.ExcelWriter(f'{folder_path}/working_file.xlsx', engine='openpyxl', mode='a') as writer:\n",
        "        result_df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
        "\n",
        "    print(f\"Saved the results to {sheet_name} in {folder_path}\")\n",
        "\n",
        "    return result_df"
      ],
      "metadata": {
        "id": "I044-r3EuqyR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def append_to_excel(working_file_path, sheet_name, result_row):\n",
        "    # Create a DataFrame from the result row\n",
        "    new_data = pd.DataFrame([result_row])\n",
        "\n",
        "    if not os.path.exists(working_file_path):\n",
        "        # If the file doesn't exist, write new data to a new file\n",
        "        with pd.ExcelWriter(working_file_path, engine='openpyxl') as writer:\n",
        "            new_data.to_excel(writer, sheet_name=sheet_name, index=False)\n",
        "    else:\n",
        "        # If the file exists, read the existing data and append the new row\n",
        "        with pd.ExcelWriter(working_file_path, engine='openpyxl', mode='a', if_sheet_exists='overlay') as writer:\n",
        "            try:\n",
        "                # Try to read the existing sheet\n",
        "                existing_data = pd.read_excel(working_file_path, sheet_name=sheet_name)\n",
        "                updated_data = pd.concat([existing_data, new_data], ignore_index=True)\n",
        "            except ValueError:\n",
        "                # If the sheet doesn't exist, just use the new data\n",
        "                updated_data = new_data\n",
        "\n",
        "            # Write/overwrite the sheet with the updated data\n",
        "            updated_data.to_excel(writer, sheet_name=sheet_name, index=False)"
      ],
      "metadata": {
        "id": "R9gjG5BLC9vP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def column_summary(key, context, instruction, content_column, max_number = None):\n",
        "    sheet_name = \"Analyse - Ergebnisse\"\n",
        "    if key_column not in df.columns:\n",
        "        raise ValueError(f\"Key column '{key_column}' does not exist in the DataFrame.\")\n",
        "\n",
        "    # Filter rows matching the key\n",
        "    matching_rows = df[df[key_column] == key]\n",
        "\n",
        "    # Assemble the prompt\n",
        "    header = content_column\n",
        "    responses = matching_rows[content_column].tolist()[:max_number]  # Get the first 'max_number' responses from the filtered rows\n",
        "    prompt = f\"{context}\\n{instruction}\\n{header}: \" + \" ###### \".join(str(response) for response in responses) + \" ######\\n\" + f\"{instruction}\"\n",
        "\n",
        "    api_result = call_api_4(prompt)\n",
        "\n",
        "    current_datetime = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "    # Results\n",
        "    result_row = {\n",
        "        'Datetime': current_datetime,\n",
        "        'content_column': content_column,\n",
        "        'Inputs/Prompt': api_result['prompt'],\n",
        "        'Output': api_result['response']\n",
        "    }\n",
        "\n",
        "    ### Apend goes here ###\n",
        "    append_to_excel(working_file_path, sheet_name, result_row)\n",
        "\n",
        "    print(f\"Saved the results to {sheet_name} in {working_file_path}\")\n",
        "    return result_row"
      ],
      "metadata": {
        "id": "Q1E4ndUo6IPh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def multi_column_summary(key, context, instruction, content_column, max_number=None):\n",
        "    sheet_name = \"Analyse - Ergebnisse\"\n",
        "    if key_column not in df.columns:\n",
        "            raise ValueError(f\"Key column '{key_column}' does not exist in the DataFrame.\")\n",
        "    matching_rows = df[df[key_column] == key]\n",
        "\n",
        "    # Initialize the prompt with context and instruction\n",
        "    prompt = f\"{context}\\n{instruction}\\n######\\n\"\n",
        "\n",
        "    # Append each column's responses to the prompt\n",
        "    for col in content_column:\n",
        "        column_header = col\n",
        "        responses = matching_rows[col].dropna().tolist()[:max_number]  # Get non-NaN 'max_number' responses from the filtered rows\n",
        "        column_responses = \" ###\\n\".join([column_header] + [str(response) for response in responses]) # Include the header in responses\n",
        "        prompt += f\"{column_responses}\\n###\\n\"\n",
        "\n",
        "    # Add the final separator and instruction\n",
        "    prompt += \"######\\n\" + f\"{instruction}\"\n",
        "\n",
        "        # Call the API\n",
        "    api_result = call_api_4(prompt)\n",
        "\n",
        "    # Prepare the results\n",
        "    current_datetime = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "    # Results\n",
        "    result_row = {\n",
        "        'Datetime': current_datetime,\n",
        "        'content_column': '; '.join(content_column),  # Join all column names for the record\n",
        "        'Inputs/Prompt': api_result['prompt'],\n",
        "        'Output': api_result['response']\n",
        "    }\n",
        "\n",
        "    ### Append goes here ###\n",
        "    append_to_excel(working_file_path, sheet_name, result_row)\n",
        "\n",
        "    print(f\"Saved the results to {sheet_name} in {working_file_path}\")\n",
        "    return result_row"
      ],
      "metadata": {
        "id": "Snv4D8aqFkyF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context1 = \"FlowFlex Piping ist ein mittelständisches Unternehmen, das sich auf die Herstellung von industrietauglichen Rohrverbindern spezialisiert hat. Diese Verbinder finden breite Anwendung in den Rohrsystemen von großen Gebäuden, Fabriken und städtischen Wasserversorgungssystemen.\"\n",
        "subject1 = \"Hauptthemen\"\n",
        "content_column1 = \"Welche Maßnahmen oder Initiativen könnten Ihrer Meinung nach die Mitarbeiterzufriedenheit und -bindung in Ihrem Unternehmen verbessern?\"\n",
        "\n",
        "result = find_column_topics(2, context1, subject1, content_column1)\n",
        "print(result)"
      ],
      "metadata": {
        "id": "9Uwhn4HezYE3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context2 = \"FlowFlex Piping ist ein mittelständisches Unternehmen, das sich auf die Herstellung von industrietauglichen Rohrverbindern spezialisiert hat. Diese Verbinder finden breite Anwendung in den Rohrsystemen von großen Gebäuden, Fabriken und städtischen Wasserversorgungssystemen.\"\n",
        "instruction2 = \"Dies sind Antworten auf eine Frage - was kann aus den Antworten abgeleitet werden?\"\n",
        "content_column2 = \"Welche Maßnahmen oder Initiativen könnten Ihrer Meinung nach die Mitarbeiterzufriedenheit und -bindung in Ihrem Unternehmen verbessern?\"\n",
        "\n",
        "result = column_summary(2, context2, instruction2, content_column2, max_number = 5)\n",
        "print(result)"
      ],
      "metadata": {
        "id": "xHujPRhr8oHM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context3 = \"FlowFlex Piping ist ein mittelständisches Unternehmen, das sich auf die Herstellung von industrietauglichen Rohrverbindern spezialisiert hat. Diese Verbinder finden breite Anwendung in den Rohrsystemen von großen Gebäuden, Fabriken und städtischen Wasserversorgungssystemen.\"\n",
        "instruction3 = \"Dies sind Antworten auf eine Reihe von Fragen - was sind die wichtigsten Punkte die daraus abgeleitet werden können?\"\n",
        "content_column3 = [\"Welche Chancen und Herausforderungen erkennen Sie für ihr Unternehmen?\", \"Wie würden Sie die Unternehmenskultur und das Arbeitsumfeld in Ihrer aktuellen Position beschreiben?\", \"Welche Maßnahmen oder Initiativen könnten Ihrer Meinung nach die Mitarbeiterzufriedenheit und -bindung in Ihrem Unternehmen verbessern?\"]  # List of column names to include in the prompt\n",
        "\n",
        "result = multi_column_summary(2, context3, instruction3, content_column3, max_number=5)\n",
        "print(result)"
      ],
      "metadata": {
        "id": "o6yEPSPaGf5I"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}